#### Axioms of Probability
#CBH And review (and maybe check what the textbook has to say):
![[Pasted image 20250117101555.png]]
"Uniform Sample space"
Note that labs are starting next week, these slides have all you need for the labs.

## Week 2 Slideshow:

### Conditional Probability
"A digital communication channel has an error rate of one bit per every thousand
transmitted. Errors are rare, but when they occur, they tend to occur in bursts that affect
many consecutive bits. If a single bit is transmitted, we might model the probability of an
error as $\frac{1}{1000}$ . However, if the previous bit was in error, because of the bursts, we might
believe that the probability that the next bit is in error is greater than $\frac 1 {1000}$"

How can we model this?
Conditional Probability measures the likelihood of an even when additional information becomes available. We want to measure the probability of the event B = {next bit has an error} given that the event A = {Previous bit has an error} has occurred.

The **conditional probability** of an event B given an event A with $P(A)>0$, is denoted $P(B|A)$ and is given by the formula:
$$
P(B|A) = \frac{P(B\cap A)}{P(A)}
$$
This is the "formal definition of conditional probability".

This can be displayed by venn diagrams: 
- Venn diagrams for events A and B. 
- Let's say we know that the event lies somewhere in A,
- How likely is it that it lies in B? Well the ratio of the overlap ($P(B\cap A$)) over all of A ($P(A)$).

![[Pasted image 20250117102525.png]]
$P(A|B_1) = 1$
$P(A|B_3)=0$, as $A\cap B_3=\emptyset$, 
$P(\emptyset) = 0$ ; good thing to write

![[Pasted image 20250117103250.png]]
This is a *uniform sample space* question
A denotes the event that the disk has high shock resistance, and B denote the event that a disk has high scratch resistance.
$P(A) = \frac{\#(A)}{\#(S)} = \frac{86}{100} = 0.86$ ; similarly $P(B) = \frac{79}{100} = 0.79$
$$
P(A|B)=\frac{P(A\cap B)}{P(B)}=\frac{\#(A\cap B)/100}{\#(B)/100}=\frac{\#(A\cap B)}{\#(B)}=\frac{70}{79}=0.89
$$
---
Show that if A,B are mutually exclusive sets, then: $P(A\cup B | C) = P(A|C) + P(B|C)$ 
Use the rule: $P(A\cup B) = P(A)+P(B)$ (ONLY when A and B are mutually exclusive) and the conditional probability rule,
$$
P(A\cup B | C) = \frac{P((A\cup B)\cap C)}{P(C)} = \frac{P((A\cap C) \cup (B \cap C))}{P(C)} = \frac{P(A\cap C) + P(B\cap C)}{P(C)}
$$
$$
=\frac{P(A\cap C)}{P(C)}+\frac{P(B\cap C)}{P(C)} = P(A|C) + P(B|C)
$$

---
Show that $P(B|A) \ge 1- \frac{P(B')}{P(A)}$
$$
\frac{P(B \cap A)}{P(A)} \ge 1- \frac{P(B')}{P(A)} ; 
$$
Remember that $1-P(B)=P(B')$

### Multiplication and Total Probability Rule
#CBH and review all of this and read textbook!
**Multiplication Rule:**
"When conditional probability between two events is known, the probability of the intersection of the two events can be computed by the multiplication rule"
$$P(A\cap B) = P(B|A)P(A)=P(A|B)P(B)$$

Let S be a sample space. A collection of events $E_1, E_2, ... E_k$ such that $E_1 \cup E_2 \cup ... \cup E_k=S$ is said to be **exhaustive**.
Assume that $E_1, E_2, ..., E_k$ are $k$ mutually exclusive and exhaustive sets. Then for any set $B$ we have that:
$P(B)=P(B|E_1)P(E_1)+P(B|E_2)P(E_2)+...+P(B|E_k)P(E_k)$

PP3:
A batch of 350 samples, 8 are defective, two are selected from batch at random, *without replacement*.
1. What is the probability the second one selected is defective given that the first one was defective
2. What is the probability that both are defective
3. What is the probability that both are acceptable
4. What is the probability the second one selected is defective.

A: The first one is defective
B: The second one is defective
Q1:
$$P(B|A) = \frac{7}{349}$$
Q2: 
$$P(A\cap B)=P(B|A)\cdot P(A) = \frac{7}{349} \cdot \frac{8}{350}$$
Q3:
$$P(A'\cap B') = P(B'|A')\cdot P(A') = \frac{341}{349} \cdot \frac{342}{350}$$
^ The numerator of $P(B'|A')$ is 341 as we've "already picked" a non defective sample: $A'$

Q4:
$$P(B) = P(B|A) \cdot P(A)+P(B|A')\cdot P(A')=\frac{7}{349}\cdot \frac{8}{350} + \frac{8}{349}\cdot \frac{342}{350}$$
^ (Total Probability Rule)

### Independence
Two events A, B are said to be *independent* if $P(A\cap B)= P(A)P(B)$
This illustrates: two events are independent if the occurrence of one does not affect the probability of the other.
**Proposition**:
Let A, B be events with $P(B), P(A) > 0$, then A,B, are independent iff one of the following holds:
- $P(B|A)=P(B)$
- $P(A|B)=P(A)$

Debunking misconception:
Mutually exclusive sets with non-zero probability are *dependent* sets
A, B are independent sets if the percentage of $A\cap B$ in $B$ is the same as the percentage of $A$ in $S$
![[Pasted image 20250117123621.png]]
$P(A|B) = \frac{A\cap B}{B}=P(A)$ #CBH Check this!

